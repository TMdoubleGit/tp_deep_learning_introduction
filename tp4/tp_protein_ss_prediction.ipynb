{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 16:58:34.959542: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-19 16:58:34.960079: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-19 16:58:35.037041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-19 16:58:36.844602: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-19 16:58:36.845126: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers, ops\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config a fournir aux etudiants.\n",
    "maxlen = 128\n",
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chargez votre dataset, et previsualisez un echantillon de celui-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pdb_id chain_code                              seq  \\\n",
      "0   1MZW          B  EVKASLRALGEPITLFGEGPAERRERLRNIL   \n",
      "1   1P9I          A  MDQLNALLASLEAENKQLKAKVEELLAKVGE   \n",
      "2   3HFE          B  GARGSNTIGARLNRVEDKVTQLDQRLALITD   \n",
      "3   3LJM          C  *EWEALEKKCAALESKLQALEKKLEALEHG*   \n",
      "4   4PND          B  *GNILQKIENILKKIENILWKIENILQKIEG   \n",
      "\n",
      "                              sst3  len  \n",
      "0  CHHHHHHHCCCCCEECCCCHHHHHHHHHHHC   31  \n",
      "1  CCCHHHHHHHHHHHHHHHHHHHHHHHHHHCC   31  \n",
      "2  CCCCCCCHHHHHHHHHHHHHHHHHHHHHHCC   31  \n",
      "3  CCHHHHHHHHHHHHHHHHHHHHHHHHHHCCC   31  \n",
      "4  CCCHHHHHHHHHHHHHHHHHHHHHHHHHHHC   31  \n"
     ]
    }
   ],
   "source": [
    "csv_path = \"dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df = df.dropna(subset=[\"seq\", \"sst3\"]).reset_index(drop=True)\n",
    "df = df[df[\"seq\"].str.len() == df[\"sst3\"].str.len()].reset_index(drop=True)\n",
    "\n",
    "sequences = df[\"seq\"].astype(str).tolist()\n",
    "labels_ss = df[\"sst3\"].astype(str).tolist()\n",
    "\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encodez les acides amines ainsi que les structures secondaires correspondantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_chars = sorted({c for seq in sequences for c in seq})\n",
    "\n",
    "aa_to_idx = {c: i + 1 for i, c in enumerate(aa_chars)}\n",
    "idx_to_aa = {i + 1: c for i, c in enumerate(aa_chars)}\n",
    "vocab_size = len(aa_to_idx) + 1\n",
    "\n",
    "ss_to_idx = {\"H\": 0, \"E\": 1, \"C\": 2}\n",
    "idx_to_ss = {v: k for k, v in ss_to_idx.items()}\n",
    "num_classes = 3\n",
    "\n",
    "encoded_seqs = [[aa_to_idx.get(c, 0) for c in seq] for seq in sequences]\n",
    "\n",
    "encoded_ss = [[ss_to_idx.get(c, 2) for c in ss] for ss in labels_ss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Preparez vos vecteurs de train et prediction (X et y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keras.utils.pad_sequences(\n",
    "    encoded_seqs,\n",
    "    maxlen=maxlen,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\",\n",
    "    value=0,\n",
    ")\n",
    "\n",
    "y = keras.utils.pad_sequences(\n",
    "    encoded_ss,\n",
    "    maxlen=maxlen,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\",\n",
    "    value=-1,\n",
    ")\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Creez une classe TransformerBlock comprenant deux methodes, init() et call()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Creez une classe TokenAndPositionEmbedding comprenant trois methodes, init(), call(), compute_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embed_dim,\n",
    "            mask_zero=True,\n",
    "        )\n",
    "        self.pos_emb = layers.Embedding(\n",
    "            input_dim=maxlen,\n",
    "            output_dim=embed_dim,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_len = ops.shape(x)[-1]\n",
    "        positions = ops.arange(start=0, stop=seq_len, step=1)\n",
    "        pos = self.pos_emb(positions)\n",
    "        tok = self.token_emb(x)\n",
    "        return tok + pos\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return self.token_emb.compute_mask(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Implementez votre modele avec un layer d'embedding puis deux block Transformers consecutifs et un layer dense de sortie s'appuyant sur la fonction d'activation softmax. Vous pourrez afficher votre model avec model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 16:58:38.281105: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2025-11-19 16:58:38.281156: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-11-19 16:58:38.281162: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: madeleine\n",
      "2025-11-19 16:58:38.281165: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: madeleine\n",
      "2025-11-19 16:58:38.281321: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 580.95.5\n",
      "2025-11-19 16:58:38.281342: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 550.163.1\n",
      "2025-11-19 16:58:38.281347: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:287] kernel version 550.163.1 does not match DSO version 580.95.5 -- cannot find working devices in this configuration\n",
      "/home/madeleine/michelweil/tmichel-/upc_tp/tp4/venv/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'transformer_block' (of type TransformerBlock) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,630,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m38,400\u001b[0m │\n",
       "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m2,630,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m2,630,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │           \u001b[38;5;34m771\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,299,459</span> (20.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,299,459\u001b[0m (20.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,299,459</span> (20.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,299,459\u001b[0m (20.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"transformer\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Redigez deux methodes loss et accuracy afin d'ignorer le padding des sequences passees dans le modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    mask = ops.cast(y_true >= 0, \"float32\")\n",
    "    y_true_clipped = ops.maximum(y_true, 0)\n",
    "\n",
    "    scce = keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=False,\n",
    "        reduction=\"none\",\n",
    "    )\n",
    "    loss_per_token = scce(y_true_clipped, y_pred)\n",
    "    loss_per_token = loss_per_token * mask\n",
    "\n",
    "    return ops.sum(loss_per_token) / (ops.sum(mask) + 1e-9)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    mask = ops.cast(y_true >= 0, \"float32\")\n",
    "    y_true_clipped = ops.maximum(y_true, 0)\n",
    "\n",
    "    y_pred_labels = ops.argmax(y_pred, axis=-1)\n",
    "    matches = ops.cast(ops.equal(y_true_clipped, y_pred_labels), \"float32\")\n",
    "    matches = matches * mask\n",
    "    return ops.sum(matches) / (ops.sum(mask) + 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Preparez des callbacks (earlyStopping, ajustement du learning rate), puis compilez votre modele et entrainez le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.5151 - loss: 1.0053 - val_accuracy: 0.5206 - val_loss: 0.9718 - learning_rate: 3.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 246ms/step - accuracy: 0.5372 - loss: 0.9500 - val_accuracy: 0.5377 - val_loss: 0.9534 - learning_rate: 3.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 246ms/step - accuracy: 0.5431 - loss: 0.9410 - val_accuracy: 0.5355 - val_loss: 0.9488 - learning_rate: 3.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 248ms/step - accuracy: 0.5453 - loss: 0.9383 - val_accuracy: 0.5437 - val_loss: 0.9358 - learning_rate: 3.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 248ms/step - accuracy: 0.5484 - loss: 0.9336 - val_accuracy: 0.5478 - val_loss: 0.9328 - learning_rate: 3.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 248ms/step - accuracy: 0.5522 - loss: 0.9275 - val_accuracy: 0.5430 - val_loss: 0.9361 - learning_rate: 3.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 247ms/step - accuracy: 0.5575 - loss: 0.9197 - val_accuracy: 0.5533 - val_loss: 0.9261 - learning_rate: 3.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 246ms/step - accuracy: 0.5619 - loss: 0.9139 - val_accuracy: 0.5574 - val_loss: 0.9193 - learning_rate: 3.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 246ms/step - accuracy: 0.5769 - loss: 0.8947 - val_accuracy: 0.5771 - val_loss: 0.8918 - learning_rate: 3.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 248ms/step - accuracy: 0.6040 - loss: 0.8573 - val_accuracy: 0.6012 - val_loss: 0.8662 - learning_rate: 3.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 242ms/step - accuracy: 0.6246 - loss: 0.8277 - val_accuracy: 0.6164 - val_loss: 0.8431 - learning_rate: 3.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 247ms/step - accuracy: 0.6335 - loss: 0.8141 - val_accuracy: 0.6184 - val_loss: 0.8359 - learning_rate: 3.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 243ms/step - accuracy: 0.6407 - loss: 0.8011 - val_accuracy: 0.6263 - val_loss: 0.8251 - learning_rate: 3.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 242ms/step - accuracy: 0.6475 - loss: 0.7891 - val_accuracy: 0.6296 - val_loss: 0.8220 - learning_rate: 3.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 228ms/step - accuracy: 0.6510 - loss: 0.7832 - val_accuracy: 0.6227 - val_loss: 0.8339 - learning_rate: 3.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 235ms/step - accuracy: 0.6540 - loss: 0.7761 - val_accuracy: 0.6298 - val_loss: 0.8315 - learning_rate: 3.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 284ms/step - accuracy: 0.6600 - loss: 0.7664 - val_accuracy: 0.6254 - val_loss: 0.8528 - learning_rate: 3.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 276ms/step - accuracy: 0.6778 - loss: 0.7341 - val_accuracy: 0.6389 - val_loss: 0.8179 - learning_rate: 1.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 280ms/step - accuracy: 0.6837 - loss: 0.7223 - val_accuracy: 0.6390 - val_loss: 0.8312 - learning_rate: 1.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 263ms/step - accuracy: 0.6879 - loss: 0.7139 - val_accuracy: 0.6360 - val_loss: 0.8343 - learning_rate: 1.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 269ms/step - accuracy: 0.6911 - loss: 0.7067 - val_accuracy: 0.6363 - val_loss: 0.8316 - learning_rate: 1.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 243ms/step - accuracy: 0.7048 - loss: 0.6803 - val_accuracy: 0.6385 - val_loss: 0.8388 - learning_rate: 7.5000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 244ms/step - accuracy: 0.7095 - loss: 0.6710 - val_accuracy: 0.6367 - val_loss: 0.8506 - learning_rate: 7.5000e-05\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=loss,\n",
    "    metrics=[accuracy],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=30,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Enregistrez les courbes d'apprentissage dans training_panels.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel sauvegardé sous : training_panels.png\n"
     ]
    }
   ],
   "source": [
    "def plot_history_panels(history, out_path=\"training_panels.png\"):\n",
    "\n",
    "    train_loss = history.history.get(\"loss\", [])\n",
    "    val_loss = history.history.get(\"val_loss\", [])\n",
    "    train_acc = history.history.get(\"accuracy\", [])\n",
    "    val_acc = history.history.get(\"val_accuracy\", [])\n",
    "\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "    ax = axs[0]\n",
    "    ax.plot(epochs, train_loss, label=\"Train loss\")\n",
    "    ax.plot(epochs, val_loss, label=\"Val loss\", linestyle=\"--\")\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.plot(epochs, train_acc, label=\"Train accuracy\")\n",
    "    ax.plot(epochs, val_acc, label=\"Val accuracy\", linestyle=\"--\")\n",
    "    ax.set_title(\"Accuracy\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Panel sauvegardé sous : {out_path}\")\n",
    "\n",
    "plot_history_panels(history, out_path=\"training_panels.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Ecrire une fonction permettant de tirer un echantillon au hasard de notre dataset, et d'effectuer une prediction a partir de la sequence d'AA. Comparez votre prediction avec la ss3 reelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Exemple tiré au hasard ===\n",
      "Séquence : GIQPVISAQEQETQIVLYGKLVEARQKHANKMDVPPAILATNKILVDMAKMRPTTVENVKRIDGVSEGKAAMLAPLLEVIKHFCQTNSVQTDLFSSTKPQEEQ\n",
      "Structure réelle : CCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHCCHHHHHHHHHHCCCCHHHHCCCCCCCHHHHHHCHHHHHHHHHHHHHCCCCCCCCCCCCCCCCC\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Structure prédite : CCCCCCCHHHHHHHHHHHHHHHHHHHHHHCHCCCCCCEEHHCHHHHHHHHCCCCCHHEEEECCCCCHHHHHHHHHHHHHHHHHHCCCCCCCCEEECCCCCCCC\n",
      "=============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('GIQPVISAQEQETQIVLYGKLVEARQKHANKMDVPPAILATNKILVDMAKMRPTTVENVKRIDGVSEGKAAMLAPLLEVIKHFCQTNSVQTDLFSSTKPQEEQ',\n",
       " 'CCCCCCCHHHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHCCHHHHHHHHHHCCCCHHHHCCCCCCCHHHHHHCHHHHHHHHHHHHHCCCCCCCCCCCCCCCCC',\n",
       " 'CCCCCCCHHHHHHHHHHHHHHHHHHHHHHCHCCCCCCEEHHCHHHHHHHHCCCCCHHEEEECCCCCHHHHHHHHHHHHHHHHHHCCCCCCCCEEECCCCCCCC')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_random_sequence(model, df, maxlen, aa_to_idx, idx_to_ss):\n",
    "    row = df.sample(1).iloc[0]\n",
    "    seq = row[\"seq\"]\n",
    "    true_ss = row[\"sst3\"]\n",
    "\n",
    "    print(\"\\n=== Exemple tiré au hasard ===\")\n",
    "    print(\"Séquence :\", seq)\n",
    "    print(\"Structure réelle :\", true_ss)\n",
    "\n",
    "    encoded = [aa_to_idx.get(c, 0) for c in seq]\n",
    "    encoded = keras.utils.pad_sequences(\n",
    "        [encoded], maxlen=maxlen, padding=\"post\", truncating=\"post\"\n",
    "    )\n",
    "\n",
    "    pred = model.predict(encoded)[0]\n",
    "    pred_labels = pred.argmax(axis=-1)\n",
    "    pred_ss3 = \"\".join(idx_to_ss[i] for i in pred_labels)\n",
    "\n",
    "    print(\"Structure prédite :\", pred_ss3[:len(seq)])\n",
    "    print(\"=============================\\n\")\n",
    "\n",
    "    return seq, true_ss, pred_ss3[:len(seq)]\n",
    "\n",
    "\n",
    "predict_random_sequence(model, df, maxlen, aa_to_idx, idx_to_ss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
